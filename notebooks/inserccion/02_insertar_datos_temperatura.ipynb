{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inserción de las temperatuuras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importaciones necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymysql\n",
    "from pymysql.constants import CLIENT\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargar las variables de entorno desde el archivo .env\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "# Obtener los parámetros de conexión\n",
    "DB_HOST = os.getenv('DB_HOST')\n",
    "DB_USER = os.getenv('DB_USER')\n",
    "DB_PASSWORD = os.getenv('DB_PASSWORD')\n",
    "DB_NAME = os.getenv('DB_NAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conexión a la base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "conexion = pymysql.connect(\n",
    "    host=DB_HOST,\n",
    "    user=DB_USER,\n",
    "    password=DB_PASSWORD,\n",
    "    database=DB_NAME,\n",
    "    client_flag=CLIENT.MULTI_STATEMENTS\n",
    ")\n",
    "cursor = conexion.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga y Exploración Inicial\n",
    "\n",
    "En esta sección se carga el dataset y se realiza un análisis exploratorio preliminar para conocer su estructura, dimensiones y calidad. Se muestran las primeras filas, se obtienen estadísticas descriptivas y se revisa la presencia de valores nulos o duplicados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cabezera del DataFrame original: \n",
      "   Area Code         Area  Months Code    Months  Element Code  \\\n",
      "0          2  Afghanistan         7001   January          7271   \n",
      "1          2  Afghanistan         7001   January          6078   \n",
      "2          2  Afghanistan         7002  February          7271   \n",
      "3          2  Afghanistan         7002  February          6078   \n",
      "4          2  Afghanistan         7003     March          7271   \n",
      "\n",
      "              Element Unit  Y1961  Y1962  Y1963  ...  Y2010  Y2011  Y2012  \\\n",
      "0  Temperature change   °C  0.777  0.062  2.744  ...  3.601  1.179 -0.583   \n",
      "1  Standard Deviation   °C  1.950  1.950  1.950  ...  1.950  1.950  1.950   \n",
      "2  Temperature change   °C -1.743  2.465  3.919  ...  1.212  0.321 -3.201   \n",
      "3  Standard Deviation   °C  2.597  2.597  2.597  ...  2.597  2.597  2.597   \n",
      "4  Temperature change   °C  0.516  1.336  0.403  ...  3.390  0.748 -0.527   \n",
      "\n",
      "   Y2013  Y2014  Y2015  Y2016  Y2017  Y2018  Y2019  \n",
      "0  1.233  1.755  1.943  3.416  1.201  1.996  2.951  \n",
      "1  1.950  1.950  1.950  1.950  1.950  1.950  1.950  \n",
      "2  1.494 -3.187  2.699  2.251 -0.323  2.705  0.086  \n",
      "3  2.597  2.597  2.597  2.597  2.597  2.597  2.597  \n",
      "4  2.246 -0.076 -0.497  2.296  0.834  4.418  0.234  \n",
      "\n",
      "[5 rows x 66 columns]\n",
      "Dimensiones del DataFrame original: \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9656 entries, 0 to 9655\n",
      "Data columns (total 66 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Area Code     9656 non-null   int64  \n",
      " 1   Area          9656 non-null   object \n",
      " 2   Months Code   9656 non-null   int64  \n",
      " 3   Months        9656 non-null   object \n",
      " 4   Element Code  9656 non-null   int64  \n",
      " 5   Element       9656 non-null   object \n",
      " 6   Unit          9656 non-null   object \n",
      " 7   Y1961         8287 non-null   float64\n",
      " 8   Y1962         8322 non-null   float64\n",
      " 9   Y1963         8294 non-null   float64\n",
      " 10  Y1964         8252 non-null   float64\n",
      " 11  Y1965         8281 non-null   float64\n",
      " 12  Y1966         8364 non-null   float64\n",
      " 13  Y1967         8347 non-null   float64\n",
      " 14  Y1968         8345 non-null   float64\n",
      " 15  Y1969         8326 non-null   float64\n",
      " 16  Y1970         8308 non-null   float64\n",
      " 17  Y1971         8303 non-null   float64\n",
      " 18  Y1972         8323 non-null   float64\n",
      " 19  Y1973         8394 non-null   float64\n",
      " 20  Y1974         8374 non-null   float64\n",
      " 21  Y1975         8280 non-null   float64\n",
      " 22  Y1976         8209 non-null   float64\n",
      " 23  Y1977         8257 non-null   float64\n",
      " 24  Y1978         8327 non-null   float64\n",
      " 25  Y1979         8290 non-null   float64\n",
      " 26  Y1980         8283 non-null   float64\n",
      " 27  Y1981         8276 non-null   float64\n",
      " 28  Y1982         8237 non-null   float64\n",
      " 29  Y1983         8205 non-null   float64\n",
      " 30  Y1984         8259 non-null   float64\n",
      " 31  Y1985         8216 non-null   float64\n",
      " 32  Y1986         8268 non-null   float64\n",
      " 33  Y1987         8284 non-null   float64\n",
      " 34  Y1988         8273 non-null   float64\n",
      " 35  Y1989         8257 non-null   float64\n",
      " 36  Y1990         8239 non-null   float64\n",
      " 37  Y1991         8158 non-null   float64\n",
      " 38  Y1992         8354 non-null   float64\n",
      " 39  Y1993         8315 non-null   float64\n",
      " 40  Y1994         8373 non-null   float64\n",
      " 41  Y1995         8409 non-null   float64\n",
      " 42  Y1996         8439 non-null   float64\n",
      " 43  Y1997         8309 non-null   float64\n",
      " 44  Y1998         8370 non-null   float64\n",
      " 45  Y1999         8324 non-null   float64\n",
      " 46  Y2000         8342 non-null   float64\n",
      " 47  Y2001         8241 non-null   float64\n",
      " 48  Y2002         8312 non-null   float64\n",
      " 49  Y2003         8390 non-null   float64\n",
      " 50  Y2004         8415 non-null   float64\n",
      " 51  Y2005         8424 non-null   float64\n",
      " 52  Y2006         8503 non-null   float64\n",
      " 53  Y2007         8534 non-null   float64\n",
      " 54  Y2008         8475 non-null   float64\n",
      " 55  Y2009         8419 non-null   float64\n",
      " 56  Y2010         8435 non-null   float64\n",
      " 57  Y2011         8437 non-null   float64\n",
      " 58  Y2012         8350 non-null   float64\n",
      " 59  Y2013         8427 non-null   float64\n",
      " 60  Y2014         8377 non-null   float64\n",
      " 61  Y2015         8361 non-null   float64\n",
      " 62  Y2016         8348 non-null   float64\n",
      " 63  Y2017         8366 non-null   float64\n",
      " 64  Y2018         8349 non-null   float64\n",
      " 65  Y2019         8365 non-null   float64\n",
      "dtypes: float64(59), int64(3), object(4)\n",
      "memory usage: 4.9+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "ruta = '../../data/fuentes/climaticos/Environment_Temperature_change_E_All_Data_NOFLAG.csv'\n",
    "df_original = pd.read_csv(ruta, encoding='latin-1', sep=',')\n",
    "print('Cabezera del DataFrame original: ')\n",
    "print(df_original.head())\n",
    "print('Dimensiones del DataFrame original: ')\n",
    "print(df_original.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valores Nulos del Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area Code          0\n",
      "Area               0\n",
      "Months Code        0\n",
      "Months             0\n",
      "Element Code       0\n",
      "Element            0\n",
      "Unit               0\n",
      "Y1961           1369\n",
      "Y1962           1334\n",
      "Y1963           1362\n",
      "Y1964           1404\n",
      "Y1965           1375\n",
      "Y1966           1292\n",
      "Y1967           1309\n",
      "Y1968           1311\n",
      "Y1969           1330\n",
      "Y1970           1348\n",
      "Y1971           1353\n",
      "Y1972           1333\n",
      "Y1973           1262\n",
      "Y1974           1282\n",
      "Y1975           1376\n",
      "Y1976           1447\n",
      "Y1977           1399\n",
      "Y1978           1329\n",
      "Y1979           1366\n",
      "Y1980           1373\n",
      "Y1981           1380\n",
      "Y1982           1419\n",
      "Y1983           1451\n",
      "Y1984           1397\n",
      "Y1985           1440\n",
      "Y1986           1388\n",
      "Y1987           1372\n",
      "Y1988           1383\n",
      "Y1989           1399\n",
      "Y1990           1417\n",
      "Y1991           1498\n",
      "Y1992           1302\n",
      "Y1993           1341\n",
      "Y1994           1283\n",
      "Y1995           1247\n",
      "Y1996           1217\n",
      "Y1997           1347\n",
      "Y1998           1286\n",
      "Y1999           1332\n",
      "Y2000           1314\n",
      "Y2001           1415\n",
      "Y2002           1344\n",
      "Y2003           1266\n",
      "Y2004           1241\n",
      "Y2005           1232\n",
      "Y2006           1153\n",
      "Y2007           1122\n",
      "Y2008           1181\n",
      "Y2009           1237\n",
      "Y2010           1221\n",
      "Y2011           1219\n",
      "Y2012           1306\n",
      "Y2013           1229\n",
      "Y2014           1279\n",
      "Y2015           1295\n",
      "Y2016           1308\n",
      "Y2017           1290\n",
      "Y2018           1307\n",
      "Y2019           1291\n"
     ]
    }
   ],
   "source": [
    "print(df_original.isnull().sum().to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area\n",
      "American Samoa                                   184\n",
      "Antigua and Barbuda                               92\n",
      "Armenia                                         1530\n",
      "Aruba                                            158\n",
      "Azerbaijan                                      1530\n",
      "Barbados                                         122\n",
      "Belarus                                         1530\n",
      "Belgium                                         1666\n",
      "Belgium-Luxembourg                               680\n",
      "Bosnia and Herzegovina                          1530\n",
      "Burundi                                          752\n",
      "Cabo Verde                                       150\n",
      "Cayman Islands                                   266\n",
      "Central African Republic                           8\n",
      "Central Asia                                    1530\n",
      "Christmas Island                                1319\n",
      "Cocos (Keeling) Islands                            2\n",
      "Comoros                                           50\n",
      "Congo                                             20\n",
      "Cook Islands                                      98\n",
      "Costa Rica                                      1142\n",
      "Croatia                                         1530\n",
      "Czechia                                         1547\n",
      "Czechoslovakia                                   918\n",
      "Djibouti                                          78\n",
      "Dominica                                           8\n",
      "Equatorial Guinea                                 62\n",
      "Eritrea                                         1579\n",
      "Estonia                                         1530\n",
      "Eswatini                                          10\n",
      "Ethiopia                                        1547\n",
      "Ethiopia PDR                                     930\n",
      "Falkland Islands (Malvinas)                     1286\n",
      "French Southern and Antarctic Territories         56\n",
      "Gabon                                             14\n",
      "Georgia                                         1530\n",
      "Guyana                                             2\n",
      "Jamaica                                           94\n",
      "Kazakhstan                                      1530\n",
      "Kiribati                                          96\n",
      "Kyrgyzstan                                      1530\n",
      "Latvia                                          1530\n",
      "Liberia                                           18\n",
      "Lithuania                                       1530\n",
      "Luxembourg                                      1666\n",
      "Madagascar                                        10\n",
      "Malawi                                            16\n",
      "Maldives                                         210\n",
      "Marshall Islands                                1513\n",
      "Martinique                                         2\n",
      "Mayotte                                           86\n",
      "Micronesia (Federated States of)                1513\n",
      "Midway Island                                   1462\n",
      "Montenegro                                      1768\n",
      "Montserrat                                        92\n",
      "Nauru                                           1683\n",
      "Niue                                            1044\n",
      "Norfolk Island                                   152\n",
      "North Macedonia                                 1530\n",
      "Oman                                               8\n",
      "Pacific Islands Trust Territory                  996\n",
      "Palau                                           1608\n",
      "Panama                                          1070\n",
      "Pitcairn Islands                                 390\n",
      "Republic of Moldova                             1530\n",
      "Russian Federation                              1530\n",
      "Rwanda                                           752\n",
      "Réunion                                           38\n",
      "Saint Kitts and Nevis                             92\n",
      "Samoa                                            100\n",
      "Sao Tome and Principe                            156\n",
      "Serbia                                          1768\n",
      "Serbia and Montenegro                           1768\n",
      "Sierra Leone                                      46\n",
      "Singapore                                       1050\n",
      "Slovakia                                        1547\n",
      "Slovenia                                        1530\n",
      "Solomon Islands                                  162\n",
      "Somalia                                            2\n",
      "South Georgia and the South Sandwich Islands     264\n",
      "South Sudan                                     1853\n",
      "Sudan                                           1853\n",
      "Sudan (former)                                   306\n",
      "Tajikistan                                      1530\n",
      "Timor-Leste                                      414\n",
      "Tokelau                                          672\n",
      "Trinidad and Tobago                              132\n",
      "Turkmenistan                                    1530\n",
      "Turks and Caicos Islands                         156\n",
      "Tuvalu                                            14\n",
      "USSR                                             952\n",
      "Ukraine                                         1530\n",
      "Uzbekistan                                      1530\n",
      "Vanuatu                                           16\n",
      "Wake Island                                     1303\n",
      "Yemen                                            890\n",
      "Yugoslav SFR                                     952\n",
      "Zambia                                             2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jcall\\AppData\\Local\\Temp\\ipykernel_19664\\417736343.py:1: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  nulls_by_country_total = df_original.groupby('Area').apply(lambda group: group.isnull().sum().sum())\n"
     ]
    }
   ],
   "source": [
    "nulls_by_country_total = df_original.groupby('Area').apply(lambda group: group.isnull().sum().sum())\n",
    "nulls_with_data = nulls_by_country_total[nulls_by_country_total > 0]\n",
    "print(nulls_with_data.to_string())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perfilado y Limpieza de Datos\n",
    "\n",
    "Se realiza un perfilado detallado para identificar y solucionar problemas de calidad, como valores nulos o duplicados. Posteriormente, se eliminan las filas problemáticas para asegurar que el dataset esté limpio y listo para su transformación.\n",
    "\n",
    "En este caso, realizamos las transformaciones necesarias para poder insertar correctamente los datos en los paises que ya están almacenados en la base de datos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Se cargaron 248 países de la dimensión Paises\n",
      "⚠️ Se descartaron 1734 filas sin país válido\n"
     ]
    }
   ],
   "source": [
    "# ————————————————————————————————————————————————\n",
    "# Celda 1 (unificada): normalizar, excepciones, explode y mapear pais_id\n",
    "# ————————————————————————————————————————————————\n",
    "\n",
    "# 1) Normalizar 'Area' a minúsculas y sin espacios\n",
    "df_original['area_norm'] = (\n",
    "    df_original['Area']\n",
    "      .astype(str)\n",
    "      .str.strip()\n",
    "      .str.lower()\n",
    ")\n",
    "\n",
    "# 2) Cargar dimensión Paises: (codigo, nombre_en) → dict nombre_en_normalizado → codigo\n",
    "cursor.execute(\"SELECT codigo, nombre_en FROM Paises;\")\n",
    "dim_paises = {\n",
    "    nombre_en.strip().lower(): codigo\n",
    "    for codigo, nombre_en in cursor.fetchall()\n",
    "}\n",
    "\n",
    "print(f\"⚠️ Se cargaron {len(dim_paises)} países de la dimensión Paises\")\n",
    "\n",
    "# 3) Diccionario de excepciones: area_norm → nombre_en(s) exacto(s) en BD\n",
    "exceptions = {\n",
    "    'belgium-luxembourg':'belgium',\n",
    "    'british virgin islands':'virgin islands (british)',\n",
    "    'channel islands':None,\n",
    "    'china, hong kong sar':'hong kong',\n",
    "    'china, macao sar':'macao',\n",
    "    'china, mainland': None,\n",
    "    'china, taiwan province of':'taiwan (province of china)',\n",
    "    \"democratic people's republic of korea\":\"korea (the democratic people's republic of)\",\n",
    "    'democratic republic of the congo':'congo (the democratic republic of the)',\n",
    "    'ethiopia pdr':'ethiopia',\n",
    "    'falkland islands (malvinas)':'falkland islands (the) [malvinas]',\n",
    "    'french southern and antarctic territories':'french southern territories',\n",
    "    'midway island':None,\n",
    "    'namibia':None,\n",
    "    'netherlands antilles (former)':  None,\n",
    "    'pacific islands trust territory':None,\n",
    "    'pitcairn islands':'pitcairn',\n",
    "    'republic of korea':'korea (the republic of)',\n",
    "    'republic of moldova':'moldova (the republic of)',\n",
    "    'serbia and montenegro':['serbia','montenegro'],\n",
    "    'sudan (former)':['sudan','south sudan'],\n",
    "    'svalbard and jan mayen islands': 'svalbard and jan mayen',\n",
    "    'turkey':'türkiye',\n",
    "    'united republic of tanzania':'tanzania, the united republic of',\n",
    "    'united states virgin islands':'virgin islands (u.s.)',\n",
    "    'ussr':None,\n",
    "    'wake island':None,\n",
    "    'wallis and futuna islands':'wallis and futuna',\n",
    "}\n",
    "\n",
    "# 4) Mapear area_norm → area_db_name (str, list o NaN)\n",
    "df_original['area_db_name'] = df_original['area_norm'].map(\n",
    "    lambda x: exceptions[x] if x in exceptions else x\n",
    ")\n",
    "\n",
    "# 5) Asegurar listas y 'explode' para casos múltiples\n",
    "df_original['area_db_list'] = df_original['area_db_name'].apply(\n",
    "    lambda v: [] if v is None else (v if isinstance(v, list) else [v])\n",
    ")\n",
    "df_original = df_original.explode('area_db_list')\n",
    "\n",
    "# 6) Mapear area_db_list (nombre_en normalizado) → codigo\n",
    "df_original['pais_id'] = (\n",
    "    df_original['area_db_list']\n",
    "      .str.strip()\n",
    "      .str.lower()\n",
    "      .map(dim_paises)\n",
    ")\n",
    "\n",
    "# 7) Filtrar fuera filas sin mapeo válido\n",
    "antes = len(df_original)\n",
    "df_original = df_original[df_original['pais_id'].notna()]\n",
    "print(f\"⚠️ Se descartaron {antes - len(df_original)} filas sin país válido\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este paso se aplican transformaciones para adaptar los datos a la estructura requerida. Por ejemplo, se transforma el campo `Months Code` en un identificador de período que servirá para relacionar los datos con la tabla de dimensiones `Periodos` en la base de datos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cambio_temperatura_anual: 13865 filas, pais_id nulos = 0\n"
     ]
    }
   ],
   "source": [
    "# 1) Definir las columnas de años\n",
    "year_columns = [c for c in df_original.columns if c.startswith('Y')]\n",
    "\n",
    "# 2) Filtro anual (Months Code = 7020)\n",
    "anual_filter = df_original['Months Code'] == 7020\n",
    "\n",
    "# 3) Filtro por tipo de parámetro (variación de temperatura)\n",
    "cambio_filter = df_original['Element'] == 'Temperature change'\n",
    "\n",
    "# 4) Función para pivotar (melt) e incluir `pais_id`\n",
    "def crear_dataset(filtro_periodo, filtro_param, df):\n",
    "    df_temp = df[filtro_periodo & filtro_param].copy()\n",
    "    df_temp = pd.melt(\n",
    "        df_temp,\n",
    "        id_vars=['pais_id', 'Area Code', 'area_db_list', 'Months Code', 'Unit'],\n",
    "        value_vars=year_columns,\n",
    "        var_name='Year',\n",
    "        value_name='Value'\n",
    "    )\n",
    "    df_temp['Year'] = df_temp['Year'].str.lstrip('Y').astype(int)\n",
    "    return df_temp\n",
    "\n",
    "# 5) Generar SOLO el dataset anual de cambio de temperatura\n",
    "cambio_temperatura_anual = crear_dataset(anual_filter, cambio_filter, df_original)\n",
    "\n",
    "# 6) Verificación\n",
    "print(f\"cambio_temperatura_anual: {cambio_temperatura_anual.shape[0]} filas, \"\n",
    "      f\"pais_id nulos = {cambio_temperatura_anual['pais_id'].isnull().sum()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los datos se dividen en subconjuntos (datasets) según el tipo de parámetro y el período:\n",
    "- **Derivación Estándar:** Datos para desviación estándar (mensual, trimestral, anual).\n",
    "- **Cambio de Temperatura:** Datos de cambio de temperatura (mensual, trimestral, anual)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores nulos para cambio_temperatura_anual:\n",
      "Value    1632\n",
      "\n",
      "----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datasets = {\n",
    "    \"cambio_temperatura_anual\": cambio_temperatura_anual,\n",
    "}\n",
    "\n",
    "for name, df in datasets.items():\n",
    "    print(f\"Valores nulos para {name}:\")\n",
    "    null_counts = df.isnull().sum()\n",
    "    print(null_counts[null_counts > 0].to_string() if (null_counts > 0).any() else \"Sin nulos\")\n",
    "    print(\"\\n\" + \"-\"*40 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cambio_temperatura_anual: 13865 filas originales -> 12233 filas después de eliminar nulos\n"
     ]
    }
   ],
   "source": [
    "# Eliminar nulos y duplicados únicamente del dataset anual\n",
    "for name, df in datasets.items():\n",
    "    filas_originales = df.shape[0]\n",
    "    df_clean = df.dropna()\n",
    "    df_clean = df_clean.drop_duplicates()\n",
    "    filas_limpias = df_clean.shape[0]\n",
    "    print(f\"{name}: {filas_originales} filas originales -> {filas_limpias} filas después de eliminar nulos\")\n",
    "    datasets[name] = df_clean\n",
    "\n",
    "# Reasignar variable\n",
    "cambio_temperatura_anual = datasets[\"cambio_temperatura_anual\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inserción de los datos\n",
    "\n",
    "En esta sección se realiza la inserción de los datos limpios y transformados en una base de datos MySQL. Se establecen conexiones utilizando `pymysql`, y se insertan los datos en las tablas respectivas\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparadas 12233 filas para insertar en Hechos.\n",
      "Cambios de temperatura anuales insertados correctamente en Hechos (12233 filas).\n"
     ]
    }
   ],
   "source": [
    "# Obtener el id del indicador (asegura que exista)\n",
    "cursor.execute(\"SELECT id FROM Indicadores WHERE codigo = %s LIMIT 1;\", (\"temperaturas\",))\n",
    "row = cursor.fetchone()\n",
    "if not row:\n",
    "    raise RuntimeError(\"No existe un indicador con codigo='temperaturas'\")\n",
    "indic_temp_id = row[0]\n",
    "\n",
    "# Preparar datos (solo anual)\n",
    "fact_hechos = []\n",
    "for _, row in cambio_temperatura_anual.iterrows():\n",
    "    pid  = str(row['pais_id'])\n",
    "    anio = int(row['Year'])\n",
    "    val  = float(row['Value'])\n",
    "    fact_hechos.append((pid, anio, indic_temp_id, val))\n",
    "\n",
    "print(f\"Preparadas {len(fact_hechos)} filas para insertar en Hechos.\")\n",
    "\n",
    "# INSERT con 4 placeholders\n",
    "sql_hechos = \"\"\"\n",
    "INSERT INTO Hechos \n",
    "  (pais_id, anio, indicador_id, valor)\n",
    "VALUES (%s, %s, %s, %s);\n",
    "\"\"\"\n",
    "cursor.executemany(sql_hechos, fact_hechos)\n",
    "conexion.commit()\n",
    "\n",
    "print(f\"Cambios de temperatura anuales insertados correctamente en Hechos ({len(fact_hechos)} filas).\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
